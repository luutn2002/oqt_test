{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM visualization for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'h5py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'h5py'"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from qutip.wigner import qfunc\n",
    "from qutip import coherent\n",
    "\n",
    "from tf_explain.core import GradCAM\n",
    "\n",
    "from qst_nn.models.classifier import Classifier\n",
    "from qst_nn.data.preprocess import remove_data, remap_labels, normalize\n",
    "from qst_nn.training.train_classifier import loss, optimizer\n",
    "from qst_nn.utils import plot_confusion_matrix, plot_three_husimi, cat\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scipy-cookbook.readthedocs.io/items/Matplotlib_LaTeX_Examples.html\n",
    "\n",
    "fig_width_pt = 246.0  # Get this from LaTeX using \\showthe\\columnwidth\n",
    "inches_per_pt = 1.0/72.27               # Convert pt to inch\n",
    "golden_mean = (np.sqrt(5)-1.0)/2.0         # Aesthetic ratio\n",
    "fig_width = fig_width_pt*inches_per_pt  # width in inches\n",
    "fig_height = fig_width*golden_mean      # height in inches\n",
    "fig_size =  [fig_width,fig_height]\n",
    "params = {# 'backend': 'ps',\n",
    "          'axes.labelsize': 8,\n",
    "          'font.size': 8,\n",
    "          'xtick.labelsize': 8,\n",
    "          'ytick.labelsize': 8,\n",
    "          'axes.labelpad': 1,\n",
    "          'text.usetex': False,\n",
    "          'figure.figsize': fig_size,}\n",
    "plt.rcParams.update(params)\n",
    "figpath = \"figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hilbert_size = 32\n",
    "\n",
    "xgrid = 32\n",
    "ygrid = 32\n",
    "\n",
    "xvec = np.linspace(-5, 5, xgrid)\n",
    "yvec = np.linspace(-5, 5, ygrid)\n",
    "\n",
    "\n",
    "classifier = Classifier()\n",
    "classifier.compile(optimizer=optimizer,\n",
    "                   loss=loss,\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "checkpoint_path = \"classifier/\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "classifier.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify a noisy cat and look at Grad-CAM images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(im, sigma = 0.2):\n",
    "    im = tf.keras.layers.GaussianNoise(sigma*np.max(im))(im, training=True)\n",
    "    im = im.numpy()\n",
    "    return im/np.max(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [cat(hilbert_size, 2, 0, 0), cat(hilbert_size, 2, 2, 0), cat(hilbert_size, 2, 2, 1)]\n",
    "data = [qfunc(rho, xvec, yvec) for rho in states]\n",
    "noisy_images = [normalize(add_noise(img, 0.2)) for img in data]\n",
    "\n",
    "fig, ax = plot_three_husimi(noisy_images[0], noisy_images[1], noisy_images[2],\n",
    "                            title=\"(a)                  Noisy input                       \",\n",
    "                           cmap=\"hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam_explanation(model, x, y, x_true, cutoff=0.9,\n",
    "    heatmap_weight=0.1, image_weight=0.9):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model (tf.model): A TensorFlow model with a predict function\n",
    "        x (ndarray): Data to explain which is fed to the model (might be noisy)\n",
    "        y (ndarray): Label\n",
    "        x_true (ndarray): The true underlying data (without noise). Could be same as x\n",
    "        cutoff (float, optional): Cutoff for the heatmap.\n",
    "        heatmap_weight (float, optional): The weight of the heatmap in the overlay\n",
    "        image_weight (float, optional): The weight of the image in the overlay\n",
    "    \n",
    "    Returns:\n",
    "        grads (ndarray): Array of normalized gradient values\n",
    "        heatmap_mask (ndarray[bool]): A mask of 0/1 according to the cutoff applied to\n",
    "                                      the heatmap\n",
    "        overlayed (ndarray): Array of heatmap overlayed on the image.\n",
    "    \"\"\"\n",
    "    explainer = GradCAM()\n",
    "    predicted_class = classifier.predict(x.reshape(-1, 32, 32, 1))\n",
    "    yidx = np.argmax(predicted_class, 1)[0]\n",
    "    \n",
    "    grid = explainer.explain((x.reshape(-1, 32, 32, 1),y),\n",
    "                             model, class_index=np.argmax(predicted_class))\n",
    "\n",
    "    grads = color.rgb2gray(grid)\n",
    "    heatmap_img = cv2.applyColorMap(grid, cv2.COLORMAP_JET)\n",
    "    heatmap_mask = grads > cutoff\n",
    "    \n",
    "    \n",
    "    overlayed = cv2.addWeighted(heatmap_mask.astype(np.float32), heatmap_weight,\n",
    "                                normalize(x_true.astype(np.float32).reshape(32, 32, 1)),\n",
    "                                image_weight, 0)\n",
    "    flat = x_true.astype(np.float32).ravel()\n",
    "    flat[np.argwhere(~heatmap_mask.ravel())] = 0.\n",
    "\n",
    "    return grads, heatmap_mask, normalize(flat.reshape((32, 32)))\n",
    "\n",
    "\n",
    "heatmaps = []\n",
    "overlay = []\n",
    "\n",
    "y = [3, 3, 3] # All are cat states\n",
    "\n",
    "for i in range(len(states)):\n",
    "    grads, heatmap_mask, overlayed = grad_cam_explanation(classifier, noisy_images[i], y[i], data[i], cutoff=0.8)\n",
    "    heatmaps.append(heatmap_mask)\n",
    "    overlay.append(overlayed)\n",
    "\n",
    "fig, ax = plot_three_husimi(heatmaps[0], heatmaps[1], heatmaps[2], cmap=\"jet\",\n",
    "                        title=\"(b)        Grad-CAM heatmaps                 \")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plot_three_husimi(overlay[0], overlay[1], overlay[2], cmap='jet',\n",
    "                            title=\"(c)        Heatmaps (> {}) on data        \".format(cutoff))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots in the paper\n",
    "\n",
    "The requires either the full test data file (~1.8 GB), or generating different,\n",
    "states, adding noise to them and making predictions. Then you can use\n",
    "the code below to reproduce Fig 9 from the paper.\n",
    "\n",
    "Please contact \"shahnawaz.ahmed95@gmail.com\" for the full data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"data/\"\n",
    "\n",
    "with h5py.File(datapath+\"test.h5\", 'r') as f:\n",
    "    xdata_test = f[\"x\"][()]\n",
    "    ydata_test = f[\"y\"][()]\n",
    "    \n",
    "# Data shapes\n",
    "print(\"Test x-data shape\", xdata_test.shape)\n",
    "print(\"Test y-data shape\", ydata_test.shape)\n",
    "\n",
    "xdata_test, ydata_test = remove_data(xdata_test, ydata_test, 3)\n",
    "ydata_test = remap_labels(ydata_test)\n",
    "\n",
    "\n",
    "# Any other preprocessing or removal of the data should be done before this step\n",
    "x_test, y_test = xdata_test.reshape((-1, xgrid, ygrid, 1)), ydata_test.reshape((-1,1))\n",
    "\n",
    "\n",
    "\n",
    "test_data_generator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    samplewise_center=False,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "noisy_images = []\n",
    "clean_images = []\n",
    "heatmaps = []\n",
    "overlay = []\n",
    "y_label = []\n",
    "y_pred = []\n",
    "\n",
    "cutoff = 0.9\n",
    "\n",
    "\n",
    "for idx in [25, 14, 16]:\n",
    "    x = test_data_generator.apply_transform(x_test[idx], {'theta': 16,\n",
    "                                                          'tx': .3,\n",
    "                                                          'ty': .3})\n",
    "    y = y_test[idx]\n",
    "    img = x.reshape(1, 32, 32, 1)\n",
    "    img_noisy = normalize(add_noise(img))\n",
    "    \n",
    "    grads, heatmap_mask, overlayed = grad_cam_explanation(classifier, img_noisy, y, img, cutoff=cutoff)\n",
    "    \n",
    "    overlay.append(overlayed)\n",
    "    noisy_images.append(img_noisy.reshape(32, 32))\n",
    "    clean_images.append(img.reshape(32, 32))\n",
    "    heatmaps.append(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_three_husimi(noisy_images[0], noisy_images[1], noisy_images[2],\n",
    "                            title=\"(a)                  Noisy input                       \",\n",
    "                           cmap=\"hot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_three_husimi(heatmaps[0], heatmaps[1], heatmaps[2], cmap=\"jet\",\n",
    "                            title=\"(b)        Grad-CAM heatmaps                 \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_three_husimi(overlay[0], overlay[1], overlay[2], cmap='hot',\n",
    "                            title=\"(c)        Heatmaps (> {}) on data        \".format(cutoff))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "304bacea9b9b16641736e2a98e90217724481d8203afc1cc755d453ee62a01d9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
